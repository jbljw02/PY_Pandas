{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat 메서드 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-22T17:30:16.464254Z",
     "end_time": "2023-05-22T17:30:16.577001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    a0\n",
      "B    b0\n",
      "C    c0\n",
      "D    d0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('../data/concat_1.csv')\n",
    "df2 = pd.read_csv('../data/concat_2.csv')\n",
    "df3 = pd.read_csv('../data/concat_3.csv')\n",
    "\n",
    "row_concat = pd.concat([df1, df2, df3])\n",
    "# print(row_concat.loc[3,])\n",
    "print(row_concat.iloc[0,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터프레임에 시리즈 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-22T17:32:04.989661Z",
     "end_time": "2023-05-22T17:32:05.052113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    0\n",
      "0   a0   b0   c0   d0  NaN\n",
      "1   a1   b1   c1   d1  NaN\n",
      "2   a2   b2   c2   d2  NaN\n",
      "3   a3   b3   c3   d3  NaN\n",
      "0  NaN  NaN  NaN  NaN   n1\n",
      "1  NaN  NaN  NaN  NaN   n2\n",
      "2  NaN  NaN  NaN  NaN   n3\n",
      "3  NaN  NaN  NaN  NaN   n4\n"
     ]
    }
   ],
   "source": [
    "new_row_series = pd.Series(['n1','n2','n3','n4'])\n",
    "print(pd.concat([df1, new_row_series]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 행 1개로 구성된 데이터프레임 생성하여 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-22T17:35:11.850883Z",
     "end_time": "2023-05-22T17:35:12.027409Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 6\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# print(new_row_df)\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# print(pd.concat([df1, new_row_df]))\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# print(df1.append(new_row_df))\u001B[39;00m\n\u001B[0;32m      5\u001B[0m data_dict \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn2\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn3\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mD\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn4\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdf1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m(data_dict, ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n",
      "File \u001B[1;32mC:\\Pycharm\\bigD\\venv\\lib\\site-packages\\pandas\\core\\generic.py:5989\u001B[0m, in \u001B[0;36mNDFrame.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5982\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   5983\u001B[0m     name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_names_set\n\u001B[0;32m   5984\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata\n\u001B[0;32m   5985\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessors\n\u001B[0;32m   5986\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info_axis\u001B[38;5;241m.\u001B[39m_can_hold_identifiers_and_holds_name(name)\n\u001B[0;32m   5987\u001B[0m ):\n\u001B[0;32m   5988\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[name]\n\u001B[1;32m-> 5989\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mobject\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "new_row_df = pd.DataFrame([['n1','n2','n3','n4']], columns=['A','B','C','D'])\n",
    "# print(new_row_df)\n",
    "# print(pd.concat([df1, new_row_df]))\n",
    "# print(df1.append(new_row_df))\n",
    "# data_dict = {'A':'n1', 'B':'n2', 'C':'n3', 'D':'n4'}\n",
    "# print(df1.append(data_dict, ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다양한 방법으로 데이터 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-22T17:47:10.629603Z",
     "end_time": "2023-05-22T17:47:10.711001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    a0   b0   c0   d0\n",
      "1    a1   b1   c1   d1\n",
      "2    a2   b2   c2   d2\n",
      "3    a3   b3   c3   d3\n",
      "4    a4   b4   c4   d4\n",
      "5    a5   b5   c5   d5\n",
      "6    a6   b6   c6   d6\n",
      "7    a7   b7   c7   d7\n",
      "8    a8   b8   c8   d8\n",
      "9    a9   b9   c9   d9\n",
      "10  a10  b10  c10  d10\n",
      "11  a11  b11  c11  d11\n",
      "    A   B   C   D   A   B   C   D    A    B    C    D\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n",
      "    A   A    A\n",
      "0  a0  a4   a8\n",
      "1  a1  a5   a9\n",
      "2  a2  a6  a10\n",
      "3  a3  a7  a11\n",
      "    A   B   C   D   A   B   C   D    A    B    C    D new_col_list\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8           n1\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9           n2\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10           n3\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11           n4\n",
      "   0   1   2   3   4   5   6   7    8    9    10   11\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat_i = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "print(row_concat_i)\n",
    "\n",
    "col_concat = pd.concat([df1, df2, df3], axis=1)\n",
    "print(col_concat)\n",
    "\n",
    "print(col_concat['A'])\n",
    "\n",
    "col_concat['new_col_list'] = ['n1', 'n2', 'n3', 'n4']\n",
    "print(col_concat)\n",
    "\n",
    "print(pd.concat([df1, df2, df3], axis=1, ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 공통 열과 공통 인덱스만 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-22T18:00:16.879376Z",
     "end_time": "2023-05-22T18:00:16.964165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   C   F   H\n",
      "0  a0  b0  c0  d0  a8  b8  c8  d8\n",
      "2  a2  b2  c2  d2  a9  b9  c9  d9\n"
     ]
    }
   ],
   "source": [
    "df1.columns = ['A', 'B', 'C', 'D']\n",
    "df2.columns = ['E', 'F', 'G', 'H']\n",
    "df3.columns = ['A', 'C', 'F', 'H']\n",
    "# print(df1)\n",
    "# print(type(df1))\n",
    "\n",
    "# print(df2)\n",
    "# print(df3)\n",
    "\n",
    "row_concat = pd.concat([df1, df2, df3])\n",
    "# print(row_concat)\n",
    "\n",
    "# print(pd.concat([df1, df2, df3], join='inner'))\n",
    "\n",
    "# print(pd.concat([df1, df3], ignore_index=False, join='inner'))\n",
    "\n",
    "df1.index = [0,1,2,3]\n",
    "df2.index = [4,5,6,7]\n",
    "df3.index = [0,2,5,7]\n",
    "# print(df3)\n",
    "\n",
    "col_concat = pd.concat([df1, df2, df3], axis=1)\n",
    "# print(col_concat)\n",
    "\n",
    "print(pd.concat([df1,df3], axis=1, join='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge 메서드 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-22T18:08:29.486585Z",
     "end_time": "2023-05-22T18:08:29.556433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ident   personal    family\n",
      "0      dyer    William      Dyer\n",
      "1        pb      Frank   Pabodie\n",
      "2      lake   Anderson      Lake\n",
      "3       roe  Valentina   Roerich\n",
      "4  danforth      Frank  Danforth\n"
     ]
    }
   ],
   "source": [
    "person = pd.read_csv('../data/survey_person.csv')\n",
    "site = pd.read_csv('../data/survey_site.csv')\n",
    "survey = pd.read_csv('../data/survey_survey.csv')\n",
    "visited = pd.read_csv('../data/survey_visited.csv')\n",
    "\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n",
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
      "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
      "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "# print(site)\n",
    "# print(visited)\n",
    "# print(survey)\n",
    "visited_subset = visited.loc[[0,2,6], ]\n",
    "# print(visited_subset)\n",
    "\n",
    "o2o_merge = site.merge(visited_subset, left_on='name', right_on='site')\n",
    "print(o2o_merge)\n",
    "\n",
    "m2o_merge = site.merge(visited, left_on='name', right_on='site')\n",
    "print(m2o_merge)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T18:20:33.041204Z",
     "end_time": "2023-05-22T18:20:33.180830Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   personal   family  taken person quant  reading\n",
      "0   dyer    William     Dyer    619   dyer   rad     9.82\n",
      "1   dyer    William     Dyer    619   dyer   sal     0.13\n",
      "2   dyer    William     Dyer    622   dyer   rad     7.80\n",
      "3   dyer    William     Dyer    622   dyer   sal     0.09\n",
      "4     pb      Frank  Pabodie    734     pb   rad     8.41\n",
      "5     pb      Frank  Pabodie    734     pb  temp   -21.50\n",
      "6     pb      Frank  Pabodie    735     pb   rad     7.22\n",
      "7     pb      Frank  Pabodie    751     pb   rad     4.35\n",
      "8     pb      Frank  Pabodie    751     pb  temp   -18.50\n",
      "9   lake   Anderson     Lake    734   lake   sal     0.05\n",
      "10  lake   Anderson     Lake    751   lake   sal     0.10\n",
      "11  lake   Anderson     Lake    752   lake   rad     2.19\n",
      "12  lake   Anderson     Lake    752   lake   sal     0.09\n",
      "13  lake   Anderson     Lake    752   lake  temp   -16.00\n",
      "14  lake   Anderson     Lake    837   lake   rad     1.46\n",
      "15  lake   Anderson     Lake    837   lake   sal     0.21\n",
      "16   roe  Valentina  Roerich    752    roe   sal    41.60\n",
      "17   roe  Valentina  Roerich    837    roe   sal    22.50\n",
      "18   roe  Valentina  Roerich    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "ps = person.merge(survey, left_on='ident', right_on='person')\n",
    "vs = visited.merge(survey, left_on='ident', right_on='taken')\n",
    "\n",
    "print(ps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T18:28:19.940244Z",
     "end_time": "2023-05-22T18:28:20.104853Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ident   site       dated  taken person quant  reading\n",
      "0     619   DR-1  1927-02-08    619   dyer   rad     9.82\n",
      "1     619   DR-1  1927-02-08    619   dyer   sal     0.13\n",
      "2     622   DR-1  1927-02-10    622   dyer   rad     7.80\n",
      "3     622   DR-1  1927-02-10    622   dyer   sal     0.09\n",
      "4     734   DR-3  1939-01-07    734     pb   rad     8.41\n",
      "5     734   DR-3  1939-01-07    734   lake   sal     0.05\n",
      "6     734   DR-3  1939-01-07    734     pb  temp   -21.50\n",
      "7     735   DR-3  1930-01-12    735     pb   rad     7.22\n",
      "8     735   DR-3  1930-01-12    735    NaN   sal     0.06\n",
      "9     735   DR-3  1930-01-12    735    NaN  temp   -26.00\n",
      "10    751   DR-3  1930-02-26    751     pb   rad     4.35\n",
      "11    751   DR-3  1930-02-26    751     pb  temp   -18.50\n",
      "12    751   DR-3  1930-02-26    751   lake   sal     0.10\n",
      "13    752   DR-3         NaN    752   lake   rad     2.19\n",
      "14    752   DR-3         NaN    752   lake   sal     0.09\n",
      "15    752   DR-3         NaN    752   lake  temp   -16.00\n",
      "16    752   DR-3         NaN    752    roe   sal    41.60\n",
      "17    837  MSK-4  1932-01-14    837   lake   rad     1.46\n",
      "18    837  MSK-4  1932-01-14    837   lake   sal     0.21\n",
      "19    837  MSK-4  1932-01-14    837    roe   sal    22.50\n",
      "20    844   DR-1  1932-03-22    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "print(vs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T18:28:25.222404Z",
     "end_time": "2023-05-22T18:28:25.396937Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "ps_vs = ps.merge(vs, left_on=['ident', 'taken', 'quant', 'reading'], right_on=['person', 'ident', 'quant', 'reading'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T18:29:40.020151Z",
     "end_time": "2023-05-22T18:29:40.137835Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident_x   personal   family  taken_x person_x quant  reading  ident_y   \n",
      "0     dyer    William     Dyer      619     dyer   rad     9.82      619  \\\n",
      "1     dyer    William     Dyer      619     dyer   sal     0.13      619   \n",
      "2     dyer    William     Dyer      622     dyer   rad     7.80      622   \n",
      "3     dyer    William     Dyer      622     dyer   sal     0.09      622   \n",
      "4       pb      Frank  Pabodie      734       pb   rad     8.41      734   \n",
      "5       pb      Frank  Pabodie      734       pb  temp   -21.50      734   \n",
      "6       pb      Frank  Pabodie      735       pb   rad     7.22      735   \n",
      "7       pb      Frank  Pabodie      751       pb   rad     4.35      751   \n",
      "8       pb      Frank  Pabodie      751       pb  temp   -18.50      751   \n",
      "9     lake   Anderson     Lake      734     lake   sal     0.05      734   \n",
      "10    lake   Anderson     Lake      751     lake   sal     0.10      751   \n",
      "11    lake   Anderson     Lake      752     lake   rad     2.19      752   \n",
      "12    lake   Anderson     Lake      752     lake   sal     0.09      752   \n",
      "13    lake   Anderson     Lake      752     lake  temp   -16.00      752   \n",
      "14    lake   Anderson     Lake      837     lake   rad     1.46      837   \n",
      "15    lake   Anderson     Lake      837     lake   sal     0.21      837   \n",
      "16     roe  Valentina  Roerich      752      roe   sal    41.60      752   \n",
      "17     roe  Valentina  Roerich      837      roe   sal    22.50      837   \n",
      "18     roe  Valentina  Roerich      844      roe   rad    11.25      844   \n",
      "\n",
      "     site       dated  taken_y person_y  \n",
      "0    DR-1  1927-02-08      619     dyer  \n",
      "1    DR-1  1927-02-08      619     dyer  \n",
      "2    DR-1  1927-02-10      622     dyer  \n",
      "3    DR-1  1927-02-10      622     dyer  \n",
      "4    DR-3  1939-01-07      734       pb  \n",
      "5    DR-3  1939-01-07      734       pb  \n",
      "6    DR-3  1930-01-12      735       pb  \n",
      "7    DR-3  1930-02-26      751       pb  \n",
      "8    DR-3  1930-02-26      751       pb  \n",
      "9    DR-3  1939-01-07      734     lake  \n",
      "10   DR-3  1930-02-26      751     lake  \n",
      "11   DR-3         NaN      752     lake  \n",
      "12   DR-3         NaN      752     lake  \n",
      "13   DR-3         NaN      752     lake  \n",
      "14  MSK-4  1932-01-14      837     lake  \n",
      "15  MSK-4  1932-01-14      837     lake  \n",
      "16   DR-3         NaN      752      roe  \n",
      "17  MSK-4  1932-01-14      837      roe  \n",
      "18   DR-1  1932-03-22      844      roe  \n"
     ]
    }
   ],
   "source": [
    "print(ps_vs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T18:29:46.625940Z",
     "end_time": "2023-05-22T18:29:46.821465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ident_x           dyer\n",
      "personal       William\n",
      "family            Dyer\n",
      "taken_x            619\n",
      "person_x          dyer\n",
      "quant              rad\n",
      "reading           9.82\n",
      "ident_y            619\n",
      "site              DR-1\n",
      "dated       1927-02-08\n",
      "taken_y            619\n",
      "person_y          dyer\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ps_vs.loc[0, ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T18:30:03.093680Z",
     "end_time": "2023-05-22T18:30:03.161458Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
